{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/e0xextazy/basic-feature-preprocessing-stacking-upgraded\n",
        "\n",
        "https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers\n",
        "\n",
        "https://www.kaggle.com/code/mathchi/churn-problem-for-bank-customer"
      ],
      "metadata": {
        "id": "EHfN9V22pcCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обновление датасетов"
      ],
      "metadata": {
        "id": "gX3tolH_efRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Импорт либ"
      ],
      "metadata": {
        "id": "mul6oy91Taje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost lightgbm --quiet"
      ],
      "metadata": {
        "id": "FpCmgrToV74y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c50423b-a748-4071-bd0b-e552de095a63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()  # must authenticate\n",
        "\n",
        "\n",
        "'''list all ids of files directly under folder folder_id'''\n",
        "\n",
        "def folder_list(folder_id):\n",
        "\n",
        "  from googleapiclient.discovery import build\n",
        "\n",
        "  gdrive = build('drive', 'v3').files()\n",
        "\n",
        "  res = gdrive.list(q=\"'%s' in parents\" % folder_id).execute()\n",
        "\n",
        "  return [f['id'] for f in res['files']]\n",
        "\n",
        "\n",
        "\n",
        "'''download all files from a gdrive folder to current directory'''\n",
        "\n",
        "def folder_download(folder_id):\n",
        "\n",
        "  for fid in folder_list(folder_id):\n",
        "    !gdown -q --id $fid\n",
        "\n",
        "#link='https://drive.google.com/drive/folders/1RLRFrsn4vZPFIf3qmA0nCKv9txq770fZ'\n",
        "\n",
        "folder_id=\"1RLRFrsn4vZPFIf3qmA0nCKv9txq770fZ\"\n",
        "\n",
        "folder_download(folder_id)\n",
        "!gunzip hackaton2023_train.csv.gz\n",
        "!gunzip hackaton2023_test.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWaJsYzWrNXj",
        "outputId": "ed9c3aaf-b707-4040-d5b2-b6eb166068d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1Is9nDmsC0h6AArYg_rdMUsmwCfo4J8Nzx1Bcds4EKOo \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1IcO15qD8vQt3RHiLYA0BrbrtCYoc2oq8CJRgooBpjJ4 \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1-5LyK6uUoV8-vrAqo676VVdFUGFY5UcEXhufpaZH_wA \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "gzip: hackaton2023_train.csv already exists; do you wish to overwrite (y or n)? ^C\n",
            "gzip: hackaton2023_test.csv already exists; do you wish to overwrite (y or n)? ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "\n",
        "from pprint import pprint\n",
        "from warnings import filterwarnings\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "YcokHupQTcjj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Включим логирование через MLflow"
      ],
      "metadata": {
        "id": "19HMUsZF_E3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet\n",
        "!pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcizo8QJ_Kue",
        "outputId": "e648b1e9-7010-413f-8e4e-0af3abae0414"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/731.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/731.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.8/731.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.8.1-py3-none-any.whl (19.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.3)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.23)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<15,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5.1)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.0.7)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow) (1.6.4)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, databricks-cli, alembic, gitpython, mlflow\n",
            "Successfully installed Mako-1.3.0 alembic-1.12.1 databricks-cli-0.18.0 docker-6.1.3 gitdb-4.0.11 gitpython-3.1.40 gunicorn-21.2.0 mlflow-2.8.1 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss, f1_score, roc_auc_score, mean_squared_error\n",
        "\n",
        "\n",
        "import mlflow\n",
        "mlflow.set_tracking_uri('http://79.137.194.156:5000/')\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "jKQsD6AI_EDd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Загрузка данных"
      ],
      "metadata": {
        "id": "yS9aBPaTiisK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_train(dataset_name):\n",
        "  df_train = pd.read_csv(f'train_{dataset_name}.csv', sep=',')\n",
        "\n",
        "  target = df_train['date_diff_post']\n",
        "  df_train = df_train.drop('date_diff_post', axis=1)\n",
        "\n",
        "\n",
        "  return df_train, target\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bLMGRmhqoGWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### import libs"
      ],
      "metadata": {
        "id": "AUB16IvQZFCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.multioutput import ClassifierChain\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multiclass import OutputCodeClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "#from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "3OKeii_SXN8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Preprocessing pipeline"
      ],
      "metadata": {
        "id": "p-DCDcP_XTpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Надо дописать раздельнный препроцессинг для регрессии и классификации"
      ],
      "metadata": {
        "id": "6z8nHGOhnd-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create a stacking classifier"
      ],
      "metadata": {
        "id": "YRbnGq33WJv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_metrics = []\n",
        "from functools import partial\n",
        "\n",
        "def get_metrics(y_true, y_pred, y_proba):\n",
        "  SC_RMSE = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "  ndf = [SC_RMSE]\n",
        "  columns = ['RMSE']\n",
        "  return dict(zip(columns, ndf))\n",
        "\n",
        "def prepare_submit(trained_model, X_test):\n",
        "  y_test = trained_model.predict(X_test)\n",
        "  X_submit = pd.DataFrame(X_test['customer_id'])\n",
        "  X_submit['date_post_diff'] = y_test\n",
        "  return X_submit"
      ],
      "metadata": {
        "id": "4dUh18oXWUW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#TRAIN_DATASET_NAME = 'train_user_order_aggs_v2.csv'\n",
        "#TEST_DATASET_NAME = 'test_user_order_aggs_v2.csv'\n",
        "datasets = ''.split()\n",
        "df_test = pd.read_csv(f'test_user_order_aggs_v2.csv', sep=',')\n",
        "for i, dataset_name in enumerate(datasets):\n",
        "  #dataset_name = 'user_order_aggs_v3'\n",
        "\n",
        "  df_train, target = read_train(dataset_name)\n",
        "  #dataset_name = 'user_order_aggs'\n",
        "  model_name = 'CatBoost_colab_regression_002'\n",
        "  classes = np.unique(target)\n",
        "  weights = compute_class_weight(class_weight='balanced', classes=classes, y=target)\n",
        "\n",
        "  folds = 4\n",
        "\n",
        "  # Train-Test Separation\n",
        "  X_train, X_val, y_train, y_val = train_test_split(df_train, target, test_size=(1/folds), random_state=12345)\n",
        "  model = CatBoostRegressor(random_state=13, task_type='CPU', class_weights=weights)\n",
        "  grid = {'learning_rate': [0.03, 0.1, 0.5, 0.01],\n",
        "          'depth': [4, 6, 10],\n",
        "          'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
        "          'n_estimators':[100, 1000,4000]}\n",
        "  #grid = {'learning_rate': [0.03], 'n_estimators':[10]}\n",
        "  randomized_search_result = model.randomized_search(grid,\n",
        "                                                    X=df_train,\n",
        "                                                    y=target,\n",
        "                                                    n_iter=10,\n",
        "                                                    plot=True)\n",
        "  best_params = randomized_search_result['params']\n",
        "  print(best_params)\n",
        "  trained_model = CatBoostRegressor(random_state=13, class_weights=weights, **best_params, task_type='CPU').fit(df_train, target)\n",
        "  X = X_train\n",
        "  with mlflow.start_run(run_name=f'grafML_{dataset_name}_{model_name}_Train'):\n",
        "    y_pred = trained_model.predict(X)\n",
        "    y_proba = trained_model.predict_proba(X)[:,1]\n",
        "    metrics_dict = get_metrics(y_train, y_pred, y_proba)\n",
        "\n",
        "    mlflow.log_metrics(metrics_dict)\n",
        "    mlflow.log_param('catboost', str(best_params))\n",
        "\n",
        "  X = X_val\n",
        "  with mlflow.start_run(run_name=f'grafML_{dataset_name}_{model_name}_Validation'):\n",
        "    y_pred = trained_model.predict(X)\n",
        "    y_proba = trained_model.predict_proba(X)[:,1]\n",
        "    metrics_dict = get_metrics(y_val, y_pred, y_proba)\n",
        "\n",
        "    mlflow.log_metrics(metrics_dict)\n",
        "    mlflow.log_param('catboost', str(best_params))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  X_submit = prepare_submit(trained_model, df_test)\n",
        "  X_submit.to_csv(f'{dataset_name}_{model_name}_submit.csv', index=False)\n"
      ],
      "metadata": {
        "id": "9G7SnNUbRFYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l0b0Fx36sCBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Metrics"
      ],
      "metadata": {
        "id": "eptFnROhWW8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Надо еще f1"
      ],
      "metadata": {
        "id": "i-pYR_Z8dkrG"
      }
    }
  ]
}